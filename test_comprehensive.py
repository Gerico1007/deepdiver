#!/usr/bin/env python3
"""
Comprehensive DeepDiver Test Suite
Tests all components of the DeepDiver system

Assembly Team: Jerry âš¡, Nyro â™ ï¸, Aureon ğŸŒ¿, JamAI ğŸ¸, Synth ğŸ§µ
"""

import asyncio
import os
import sys
import tempfile
from pathlib import Path

# Add current directory to path
sys.path.insert(0, '.')

from deepdiver.content_processor import ContentProcessor
from deepdiver.podcast_manager import PodcastManager
from deepdiver.session_tracker import SessionTracker
from deepdiver.notebooklm_automator import NotebookLMAutomator


class DeepDiverTestSuite:
    """Comprehensive test suite for DeepDiver components."""
    
    def __init__(self):
        """Initialize the test suite."""
        self.test_results = {}
        self.temp_dir = tempfile.mkdtemp()
        print(f"ğŸ§ª DeepDiver Comprehensive Test Suite")
        print(f"ğŸ“ Temp directory: {self.temp_dir}")
        print("=" * 60)
    
    def test_content_processor(self):
        """Test ContentProcessor functionality."""
        print("\nğŸ”§ Testing ContentProcessor...")
        
        try:
            processor = ContentProcessor()
            
            # Test with README.md
            test_file = 'README.md'
            if os.path.exists(test_file):
                # Test validation
                validation = processor.validate_file(test_file)
                self.test_results['content_validation'] = validation['success']
                print(f"  âœ… File validation: {validation['success']}")
                
                # Test content info
                info = processor.get_content_info(test_file)
                self.test_results['content_info'] = info['exists']
                print(f"  âœ… Content info: {info['file_size']} bytes, {info['file_format']}")
                
                # Test preparation
                preparation = processor.prepare_content(test_file, self.temp_dir)
                self.test_results['content_preparation'] = preparation['success']
                print(f"  âœ… Content preparation: {preparation['success']}")
            else:
                print("  âš ï¸ No test file available")
                self.test_results['content_validation'] = False
            
            return True
            
        except Exception as e:
            print(f"  âŒ ContentProcessor test failed: {e}")
            self.test_results['content_processor'] = False
            return False
    
    def test_podcast_manager(self):
        """Test PodcastManager functionality."""
        print("\nğŸ™ï¸ Testing PodcastManager...")
        
        try:
            manager = PodcastManager()
            
            # Test filename generation
            filename = manager.generate_filename('Test Podcast')
            self.test_results['filename_generation'] = bool(filename)
            print(f"  âœ… Filename generation: {filename}")
            
            # Test listing podcasts
            podcasts = manager.list_podcasts()
            self.test_results['podcast_listing'] = True
            print(f"  âœ… Podcast listing: {len(podcasts)} podcasts found")
            
            # Test content info
            info = manager.get_podcast_info('nonexistent.mp3')
            self.test_results['podcast_info'] = (info is None)
            print(f"  âœ… Podcast info handling: {info is None}")
            
            return True
            
        except Exception as e:
            print(f"  âŒ PodcastManager test failed: {e}")
            self.test_results['podcast_manager'] = False
            return False
    
    def test_session_tracker(self):
        """Test SessionTracker functionality."""
        print("\nğŸ”® Testing SessionTracker...")
        
        try:
            tracker = SessionTracker()
            
            # Test session creation
            result = tracker.start_session(ai_assistant='claude', issue_number=1)
            self.test_results['session_creation'] = result['success']
            print(f"  âœ… Session creation: {result['success']}")
            
            if result['success']:
                session_id = result['session_id']
                
                # Test writing to session
                write_result = tracker.write_to_session('Test message', 'note')
                self.test_results['session_writing'] = write_result
                print(f"  âœ… Session writing: {write_result}")
                
                # Test session status
                status = tracker.get_session_status()
                self.test_results['session_status'] = (status is not None)
                print(f"  âœ… Session status: {status['status'] if status else 'None'}")
                
                # Test listing sessions
                sessions = tracker.list_sessions()
                self.test_results['session_listing'] = (len(sessions) > 0)
                print(f"  âœ… Session listing: {len(sessions)} sessions")
                
                # Test ending session
                end_result = tracker.end_session()
                self.test_results['session_ending'] = end_result
                print(f"  âœ… Session ending: {end_result}")
            
            return True
            
        except Exception as e:
            print(f"  âŒ SessionTracker test failed: {e}")
            self.test_results['session_tracker'] = False
            return False
    
    async def test_notebooklm_automator(self):
        """Test NotebookLMAutomator functionality."""
        print("\nğŸŒ Testing NotebookLMAutomator...")
        
        try:
            automator = NotebookLMAutomator()
            
            # Test browser connection
            connection_result = await automator.connect_to_browser()
            self.test_results['browser_connection'] = connection_result
            print(f"  âœ… Browser connection: {connection_result}")
            
            if connection_result:
                # Test navigation (with shorter timeout)
                automator.timeout = 10000  # 10 seconds
                navigation_result = await automator.navigate_to_notebooklm()
                self.test_results['notebooklm_navigation'] = navigation_result
                print(f"  âœ… NotebookLM navigation: {navigation_result}")
                
                # Test authentication check
                auth_result = await automator.check_authentication()
                self.test_results['authentication_check'] = True  # This is just a check
                print(f"  âœ… Authentication check: {'Authenticated' if auth_result else 'Not authenticated'}")
            
            await automator.close()
            return True
            
        except Exception as e:
            print(f"  âŒ NotebookLMAutomator test failed: {e}")
            self.test_results['notebooklm_automator'] = False
            return False
    
    def test_integration(self):
        """Test component integration."""
        print("\nğŸ”— Testing Component Integration...")
        
        try:
            # Test that all components can work together
            processor = ContentProcessor()
            manager = PodcastManager()
            tracker = SessionTracker()
            
            # Test file processing workflow
            test_file = 'README.md'
            if os.path.exists(test_file):
                # Validate file
                validation = processor.validate_file(test_file)
                if validation['success']:
                    # Start session
                    session_result = tracker.start_session(ai_assistant='claude', issue_number=1)
                    if session_result['success']:
                        # Add document to session
                        doc_info = {'filename': test_file, 'size': validation['file_size']}
                        doc_result = tracker.add_document_to_session(doc_info)
                        
                        # Generate podcast filename
                        podcast_filename = manager.generate_filename('Integration Test Podcast')
                        
                        # End session
                        tracker.end_session()
                        
                        self.test_results['integration'] = True
                        print(f"  âœ… Integration test: Complete workflow successful")
                        print(f"  ğŸ“„ Document processed: {test_file}")
                        print(f"  ğŸ™ï¸ Podcast filename: {podcast_filename}")
                    else:
                        self.test_results['integration'] = False
                        print(f"  âŒ Integration test: Session creation failed")
                else:
                    self.test_results['integration'] = False
                    print(f"  âŒ Integration test: File validation failed")
            else:
                self.test_results['integration'] = False
                print(f"  âŒ Integration test: No test file available")
            
            return True
            
        except Exception as e:
            print(f"  âŒ Integration test failed: {e}")
            self.test_results['integration'] = False
            return False
    
    def cleanup(self):
        """Clean up test resources."""
        try:
            import shutil
            shutil.rmtree(self.temp_dir)
            print(f"\nğŸ§¹ Cleaned up temp directory: {self.temp_dir}")
        except Exception as e:
            print(f"âš ï¸ Cleanup warning: {e}")
    
    def print_results(self):
        """Print comprehensive test results."""
        print("\n" + "=" * 60)
        print("ğŸ“Š COMPREHENSIVE TEST RESULTS")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() if result)
        
        for test_name, result in self.test_results.items():
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"{test_name}: {status}")
        
        print(f"\nOverall: {passed_tests}/{total_tests} tests passed")
        
        if passed_tests == total_tests:
            print("ğŸ‰ ALL TESTS PASSED! DeepDiver is ready for production!")
        elif passed_tests >= total_tests * 0.8:
            print("âš ï¸ Most tests passed. Some issues may need attention.")
        else:
            print("âŒ Multiple test failures. Please check implementation.")
        
        print("\nâ™ ï¸ğŸŒ¿ğŸ¸ğŸ§µ Assembly Team Test Results:")
        print("Jerry âš¡: Creative technical leadership validated")
        print("Nyro â™ ï¸: Structural architecture confirmed")
        print("Aureon ğŸŒ¿: Emotional context preserved")
        print("JamAI ğŸ¸: Musical harmony maintained")
        print("Synth ğŸ§µ: Terminal orchestration verified")


async def main():
    """Main test function."""
    test_suite = DeepDiverTestSuite()
    
    try:
        # Run all tests
        test_suite.test_content_processor()
        test_suite.test_podcast_manager()
        test_suite.test_session_tracker()
        await test_suite.test_notebooklm_automator()
        test_suite.test_integration()
        
        # Print results
        test_suite.print_results()
        
        return test_suite.test_results
        
    finally:
        test_suite.cleanup()


if __name__ == "__main__":
    # Run the comprehensive test suite
    results = asyncio.run(main())
    
    # Exit with appropriate code
    total_tests = len(results)
    passed_tests = sum(1 for result in results.values() if result)
    
    if passed_tests == total_tests:
        sys.exit(0)  # All tests passed
    else:
        sys.exit(1)  # Some tests failed


